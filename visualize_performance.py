import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load the data
df = pd.read_csv('performance_results.csv')

# Set up the plotting environment
plt.style.use('ggplot')
sns.set(font_scale=1.2)
plt.figure(figsize=(15, 10))

# Create directory for saving plots
import os
if not os.path.exists('performance_plots'):
    os.makedirs('performance_plots')

# 1. Nodes Generated by Algorithm
plt.figure(figsize=(12, 6))
sns.boxplot(x='method', y='nodes_generated', data=df, palette='viridis')
plt.title('Nodes Generated by Algorithm', fontsize=16)
plt.xlabel('Algorithm', fontsize=14)
plt.ylabel('Nodes Generated', fontsize=14)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('performance_plots/nodes_by_algorithm.png', dpi=300)
plt.close()

# 2. Path Length by Algorithm
plt.figure(figsize=(12, 6))
sns.boxplot(x='method', y='path_length', data=df, palette='magma')
plt.title('Path Length by Algorithm', fontsize=16)
plt.xlabel('Algorithm', fontsize=14)
plt.ylabel('Path Length', fontsize=14)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('performance_plots/path_length_by_algorithm.png', dpi=300)
plt.close()

# 3. Execution Time by Algorithm
plt.figure(figsize=(12, 6))
sns.boxplot(x='method', y='execution_time', data=df, palette='crest')
plt.title('Execution Time by Algorithm', fontsize=16)
plt.xlabel('Algorithm', fontsize=14)
plt.ylabel('Execution Time (s)', fontsize=14)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('performance_plots/time_by_algorithm.png', dpi=300)
plt.close()

# 4. Relationship between Nodes and Path Length
plt.figure(figsize=(10, 8))
for method in df['method'].unique():
    subset = df[df['method'] == method]
    plt.scatter(subset['nodes_generated'], subset['path_length'], 
                label=method, alpha=0.7, s=100)

plt.title('Nodes Generated vs Path Length', fontsize=16)
plt.xlabel('Nodes Generated', fontsize=14)
plt.ylabel('Path Length', fontsize=14)
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('performance_plots/nodes_vs_path_length.png', dpi=300)
plt.close()

# 5. Performance by Test Case
test_cases = df['test_case'].unique()
methods = df['method'].unique()

# Average nodes by test case and method
plt.figure(figsize=(14, 8))
avg_nodes = df.pivot_table(index='test_case', columns='method', values='nodes_generated')
ax = avg_nodes.plot(kind='bar', figsize=(14, 8))
plt.title('Nodes Generated by Test Case and Method', fontsize=16)
plt.xlabel('Test Case', fontsize=14)
plt.ylabel('Nodes Generated', fontsize=14)
plt.xticks(rotation=45)
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(title='Method', fontsize=12)
plt.tight_layout()
plt.savefig('performance_plots/nodes_by_test_case.png', dpi=300)
plt.close()

# 6. Path Length by Test Case and Method
plt.figure(figsize=(14, 8))
avg_path = df.pivot_table(index='test_case', columns='method', values='path_length')
ax = avg_path.plot(kind='bar', figsize=(14, 8))
plt.title('Path Length by Test Case and Method', fontsize=16)
plt.xlabel('Test Case', fontsize=14)
plt.ylabel('Path Length', fontsize=14)
plt.xticks(rotation=45)
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(title='Method', fontsize=12)
plt.tight_layout()
plt.savefig('performance_plots/path_length_by_test_case.png', dpi=300)
plt.close()

# 7. Node Efficiency Ratio (Path Length / Nodes Generated)
df['efficiency_ratio'] = df['path_length'] / df['nodes_generated']
plt.figure(figsize=(12, 6))
sns.boxplot(x='method', y='efficiency_ratio', data=df, palette='Set2')
plt.title('Efficiency Ratio (Path Length / Nodes Generated)', fontsize=16)
plt.xlabel('Algorithm', fontsize=14)
plt.ylabel('Efficiency Ratio', fontsize=14)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('performance_plots/efficiency_ratio.png', dpi=300)
plt.close()

# Create a summary table
summary = df.groupby('method').agg({
    'execution_time': ['mean', 'std'],
    'nodes_generated': ['mean', 'std'],
    'path_length': ['mean', 'std'],
    'path_found': 'mean'
}).reset_index()

# Flatten the column hierarchy
summary.columns = ['_'.join(col).strip('_') for col in summary.columns.values]

# Rename columns for clarity
summary = summary.rename(columns={
    'method_': 'Method',
    'execution_time_mean': 'Avg Time (s)',
    'execution_time_std': 'Time Std',
    'nodes_generated_mean': 'Avg Nodes',
    'nodes_generated_std': 'Nodes Std',
    'path_length_mean': 'Avg Path Length',
    'path_length_std': 'Path Std',
    'path_found_mean': 'Success Rate'
})

# Format the numeric columns
summary['Success Rate'] = summary['Success Rate'] * 100
summary['Avg Time (s)'] = summary['Avg Time (s)'].apply(lambda x: f"{x:.6f}")
summary['Avg Nodes'] = summary['Avg Nodes'].apply(lambda x: f"{int(x)}")
summary['Avg Path Length'] = summary['Avg Path Length'].apply(lambda x: f"{x:.1f}")
summary['Success Rate'] = summary['Success Rate'].apply(lambda x: f"{x:.1f}%")

# Save the summary to CSV
summary.to_csv('performance_plots/algorithm_summary.csv', index=False)

# Print completion message
print("Performance visualizations generated in the 'performance_plots' directory")
print("Summary statistics saved as 'performance_plots/algorithm_summary.csv'") 